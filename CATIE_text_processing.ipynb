{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6fa49e-df4a-4bd0-8f44-36d15e2ff678",
   "metadata": {},
   "source": [
    "## Notebook for reading CATIE data text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "456fd6b6-f06b-4260-941e-e4d94310cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56f47496-68cc-4f9b-acc6-0122d50df793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root folder for all the data\n",
    "root_folder = r\"C:\\Users\\Senna\\Desktop\\Iigaya_lab\\catie\\catie_text_data\\catie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b19f4990-789f-4f2c-a0aa-6430d1a8f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path, text_columns_start_row=0):\n",
    "    \"\"\"\n",
    "    Processes a text file to handle numeric columns and filter NaN values.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: Path to the text file.\n",
    "    - text_columns_start_row: Row index from where to start processing text columns (default is 1).\n",
    "    \n",
    "    Returns:\n",
    "    - recombined_df: A DataFrame with filtered numeric and text columns.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path, delimiter='\\t', low_memory=False)\n",
    "    \n",
    "    # first two text columns\n",
    "    df_first_two_columns = df.iloc[text_columns_start_row:, :2]  \n",
    "    \n",
    "    # select numeric columns (all except the first two and last two)\n",
    "    df_numeric = df.iloc[text_columns_start_row:, 2:-2]  \n",
    "    \n",
    "    # convert non-numeric values to NaN. description row excluded and added back.\n",
    "    first_row = df_numeric.iloc[0]\n",
    "    rest_of_df = df_numeric.iloc[1:]\n",
    "    df_numeric = rest_of_df.apply(pd.to_numeric, errors='coerce')\n",
    "    df_numeric = pd.concat([pd.DataFrame([first_row]), df_numeric], ignore_index=True)\n",
    "\n",
    "    # retain last two text columns\n",
    "    df_last_two_columns = df.iloc[text_columns_start_row:, -2:]  # Last two columns\n",
    "    \n",
    "    # filter\n",
    "    non_nan_filtered = df_numeric.dropna()\n",
    "    \n",
    "    # Function to check if all elements except the first one are NaN\n",
    "    def should_drop(column):\n",
    "        return column[1:].isna().all()\n",
    "\n",
    "    # Identify columns to drop\n",
    "    columns_to_drop = [col for col in df_numeric.columns if should_drop(df_numeric[col])]\n",
    "\n",
    "    # Drop those columns\n",
    "    non_nan_columns = df_numeric.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # Recombine the numeric subset, first two text columns, and last two text columns\n",
    "    recombined_df = pd.concat([df_first_two_columns, non_nan_columns, df_last_two_columns], axis=1)\n",
    "\n",
    "    # Check that collection_title or promoted_subjectkey are both there\n",
    "    description_row = recombined_df.iloc[0]\n",
    "    desc_contains_collection_title = description_row.apply(lambda x: 'collection_title' in str(x)).any()\n",
    "    desc_contains_promoted_subjectkey = description_row.apply(lambda x: 'promoted_subjectkey' in str(x)).any()\n",
    "    cols_contain_collection_title = 'collection_title' in recombined_df.columns\n",
    "    cols_contain_promoted_subjectkey = 'promoted_subjectkey' in recombined_df.columns\n",
    "\n",
    "    if not desc_contains_collection_title:\n",
    "        print(\"Collection_title is missing from the column descriptions.\")\n",
    "    if not desc_contains_promoted_subjectkey:\n",
    "        print(\"Promoted_subjectkey is missing from the column descriptions.\")\n",
    "    if not cols_contain_collection_title:\n",
    "        print(\"Collection_title is missing from the column names.\")\n",
    "    if not cols_contain_promoted_subjectkey:\n",
    "        print(\"Promoted_subjectkey is missing from the column names.\")\n",
    "    if desc_contains_collection_title and desc_contains_promoted_subjectkey and cols_contain_collection_title and cols_contain_promoted_subjectkey:\n",
    "        return recombined_df\n",
    "\n",
    "def process_all_files(root_folder, file_list, text_columns_start_row=0):\n",
    "    \"\"\"\n",
    "    Processes all files in the list and returns the processed DataFrames.\n",
    "    \n",
    "    Parameters:\n",
    "    - root_folder: Root folder containing all text files.\n",
    "    - file_list: List of file names to process.\n",
    "    - text_columns_start_row: Row index from where to start processing text columns (default is 1).\n",
    "    \n",
    "    Returns:\n",
    "    - result_dict: Dictionary with file names as keys and processed DataFrames as values.\n",
    "    \"\"\"\n",
    "    result_dict = {}\n",
    "    \n",
    "    for file_name in file_list:\n",
    "        file_path = os.path.join(root_folder, file_name)\n",
    "        print(f\"Processing {file_name}...\")\n",
    "        \n",
    "        # Process the file\n",
    "        processed_df = process_file(file_path, text_columns_start_row)\n",
    "        \n",
    "        # Store the result in the dictionary\n",
    "        if isinstance(processed_df, pd.DataFrame):\n",
    "            result_dict[file_name] = processed_df\n",
    "    \n",
    "    return result_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c130cf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aesposys01.txt', 'aims01.txt', 'cata01.txt', 'cgis01.txt', 'clgry01.txt', 'dai01.txt', 'demo01.txt', 'dgsposys01.txt', 'dosecomp01.txt', 'ecg01.txt', 'endphase01.txt', 'endstudy01.txt', 'fint01.txt', 'hair01.txt', 'itaq01.txt', 'keyvars01.txt', 'lab01.txt', 'maccomp01.txt', 'macvlnce01.txt', 'med01.txt', 'meddispn01.txt', 'ndar_aggregate.txt', 'ndar_subject01.txt', 'neurobatt01.txt', 'package_info.txt', 'panss01.txt', 'qol01.txt', 'sae01.txt', 'scid_ph01.txt', 'screen01.txt', 'sf1201.txt', 'surf01.txt', 'surfq01.txt', 'timeto01.txt', 'viol01.txt', 'vitals01.txt']\n"
     ]
    }
   ],
   "source": [
    "def get_text_files(directory):\n",
    "    text_files = [f for f in os.listdir(directory) if f.endswith('.txt') and os.path.isfile(os.path.join(directory, f))]\n",
    "    return text_files\n",
    "\n",
    "root_folder = r\"C:\\Users\\Senna\\Desktop\\Iigaya_lab\\catie\\catie_text_data\\catie\"\n",
    "file_list = get_text_files(root_folder)\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "661bb096-33c7-4280-b285-71f081678d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing aesposys01.txt...\n",
      "Processing aims01.txt...\n",
      "Processing cata01.txt...\n",
      "Processing cgis01.txt...\n",
      "Processing clgry01.txt...\n",
      "Processing dai01.txt...\n",
      "Processing demo01.txt...\n",
      "Processing dgsposys01.txt...\n",
      "Processing dosecomp01.txt...\n",
      "Processing ecg01.txt...\n",
      "Processing endphase01.txt...\n",
      "Processing endstudy01.txt...\n",
      "Processing fint01.txt...\n",
      "Processing hair01.txt...\n",
      "Processing itaq01.txt...\n",
      "Processing keyvars01.txt...\n",
      "Processing lab01.txt...\n",
      "Processing maccomp01.txt...\n",
      "Processing macvlnce01.txt...\n",
      "Processing med01.txt...\n",
      "Processing meddispn01.txt...\n",
      "Processing ndar_aggregate.txt...\n",
      "Collection_title is missing from the column descriptions.\n",
      "Promoted_subjectkey is missing from the column descriptions.\n",
      "Collection_title is missing from the column names.\n",
      "Promoted_subjectkey is missing from the column names.\n",
      "Processing ndar_subject01.txt...\n",
      "Processing neurobatt01.txt...\n",
      "Processing package_info.txt...\n",
      "Collection_title is missing from the column descriptions.\n",
      "Promoted_subjectkey is missing from the column descriptions.\n",
      "Collection_title is missing from the column names.\n",
      "Promoted_subjectkey is missing from the column names.\n",
      "Processing panss01.txt...\n",
      "Processing qol01.txt...\n",
      "Processing sae01.txt...\n",
      "Processing scid_ph01.txt...\n",
      "Processing screen01.txt...\n",
      "Processing sf1201.txt...\n",
      "Processing surf01.txt...\n",
      "Processing surfq01.txt...\n",
      "Processing timeto01.txt...\n",
      "Processing viol01.txt...\n",
      "Processing vitals01.txt...\n"
     ]
    }
   ],
   "source": [
    "# Process all files and store the results in a dictionary\n",
    "processed_data = process_all_files(root_folder, file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe61ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_id</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>src_subject_id</th>\n",
       "      <th>visitid</th>\n",
       "      <th>copyid</th>\n",
       "      <th>truncvis</th>\n",
       "      <th>visday</th>\n",
       "      <th>anygenae</th>\n",
       "      <th>reportid</th>\n",
       "      <th>mdsev</th>\n",
       "      <th>...</th>\n",
       "      <th>b1_wt</th>\n",
       "      <th>b1b_wt</th>\n",
       "      <th>b2_wt</th>\n",
       "      <th>b3_wt</th>\n",
       "      <th>c_wt</th>\n",
       "      <th>p_gain</th>\n",
       "      <th>bmi_cat</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>height_std</th>\n",
       "      <th>weight_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>collection_id</td>\n",
       "      <td>dataset_id</td>\n",
       "      <td>Subject ID how it's defined in lab/project</td>\n",
       "      <td>MetaTrial Visit ID</td>\n",
       "      <td>Copy ID for multi-copy forms</td>\n",
       "      <td>Truncated Visit Number</td>\n",
       "      <td>Number of days from study baseline to date of ...</td>\n",
       "      <td>Any general adverse events (AE)</td>\n",
       "      <td>Number of AE Report by Patient</td>\n",
       "      <td>Physicians assessment of the severity of the AE</td>\n",
       "      <td>...</td>\n",
       "      <td>Phase 1/1A Baseline Weight</td>\n",
       "      <td>Phase 1B Baseline Weight</td>\n",
       "      <td>Phase 2 Baseline Weight</td>\n",
       "      <td>Phase 3 Baseline Weight</td>\n",
       "      <td>Phase-Specific CFB Weight</td>\n",
       "      <td>Phase Specific Percent Wt Gain</td>\n",
       "      <td>Body Mass Index Categorized</td>\n",
       "      <td>heart rate</td>\n",
       "      <td>Height - Standard Unit</td>\n",
       "      <td>Weight - Standard Unit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2081</td>\n",
       "      <td>8980</td>\n",
       "      <td>2341</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2081</td>\n",
       "      <td>8980</td>\n",
       "      <td>2341</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2081</td>\n",
       "      <td>8980</td>\n",
       "      <td>2341</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2081</td>\n",
       "      <td>8980</td>\n",
       "      <td>2341</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681109</th>\n",
       "      <td>2081</td>\n",
       "      <td>8976</td>\n",
       "      <td>1636</td>\n",
       "      <td>5800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>152.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681110</th>\n",
       "      <td>2081</td>\n",
       "      <td>8976</td>\n",
       "      <td>2745</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>189.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681111</th>\n",
       "      <td>2081</td>\n",
       "      <td>8976</td>\n",
       "      <td>1165</td>\n",
       "      <td>4000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>224.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681112</th>\n",
       "      <td>2081</td>\n",
       "      <td>8976</td>\n",
       "      <td>1165</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>224.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681113</th>\n",
       "      <td>2081</td>\n",
       "      <td>8976</td>\n",
       "      <td>1165</td>\n",
       "      <td>5800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>224.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681114 rows × 1239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        collection_id  dataset_id                              src_subject_id  \\\n",
       "0       collection_id  dataset_id  Subject ID how it's defined in lab/project   \n",
       "1                2081        8980                                        2341   \n",
       "2                2081        8980                                        2341   \n",
       "3                2081        8980                                        2341   \n",
       "4                2081        8980                                        2341   \n",
       "...               ...         ...                                         ...   \n",
       "681109           2081        8976                                        1636   \n",
       "681110           2081        8976                                        2745   \n",
       "681111           2081        8976                                        1165   \n",
       "681112           2081        8976                                        1165   \n",
       "681113           2081        8976                                        1165   \n",
       "\n",
       "                   visitid                        copyid  \\\n",
       "0       MetaTrial Visit ID  Copy ID for multi-copy forms   \n",
       "1                      400                             0   \n",
       "2                      400                             0   \n",
       "3                      400                             0   \n",
       "4                      400                             0   \n",
       "...                    ...                           ...   \n",
       "681109                5800                           NaN   \n",
       "681110                 200                           NaN   \n",
       "681111                4000                           NaN   \n",
       "681112                 200                           NaN   \n",
       "681113                5800                           NaN   \n",
       "\n",
       "                      truncvis  \\\n",
       "0       Truncated Visit Number   \n",
       "1                            0   \n",
       "2                            0   \n",
       "3                            0   \n",
       "4                            0   \n",
       "...                        ...   \n",
       "681109                      16   \n",
       "681110                      -1   \n",
       "681111                      18   \n",
       "681112                      -1   \n",
       "681113                       6   \n",
       "\n",
       "                                                   visday  \\\n",
       "0       Number of days from study baseline to date of ...   \n",
       "1                                                       1   \n",
       "2                                                       1   \n",
       "3                                                       1   \n",
       "4                                                       1   \n",
       "...                                                   ...   \n",
       "681109                                                487   \n",
       "681110                                                 -1   \n",
       "681111                                                505   \n",
       "681112                                                 -2   \n",
       "681113                                                161   \n",
       "\n",
       "                               anygenae                        reportid  \\\n",
       "0       Any general adverse events (AE)  Number of AE Report by Patient   \n",
       "1                                   NaN                             NaN   \n",
       "2                                   NaN                             NaN   \n",
       "3                                   NaN                             NaN   \n",
       "4                                   NaN                             NaN   \n",
       "...                                 ...                             ...   \n",
       "681109                              NaN                             NaN   \n",
       "681110                              NaN                             NaN   \n",
       "681111                              NaN                             NaN   \n",
       "681112                              NaN                             NaN   \n",
       "681113                              NaN                             NaN   \n",
       "\n",
       "                                                  mdsev  ...  \\\n",
       "0       Physicians assessment of the severity of the AE  ...   \n",
       "1                                                   1.0  ...   \n",
       "2                                                   0.0  ...   \n",
       "3                                                   0.0  ...   \n",
       "4                                                   1.0  ...   \n",
       "...                                                 ...  ...   \n",
       "681109                                              NaN  ...   \n",
       "681110                                              NaN  ...   \n",
       "681111                                              NaN  ...   \n",
       "681112                                              NaN  ...   \n",
       "681113                                              NaN  ...   \n",
       "\n",
       "                             b1_wt                    b1b_wt  \\\n",
       "0       Phase 1/1A Baseline Weight  Phase 1B Baseline Weight   \n",
       "1                              NaN                       NaN   \n",
       "2                              NaN                       NaN   \n",
       "3                              NaN                       NaN   \n",
       "4                              NaN                       NaN   \n",
       "...                            ...                       ...   \n",
       "681109                       152.0                       NaN   \n",
       "681110                       189.0                       NaN   \n",
       "681111                       220.0                       NaN   \n",
       "681112                       220.0                       NaN   \n",
       "681113                       220.0                       NaN   \n",
       "\n",
       "                          b2_wt                    b3_wt  \\\n",
       "0       Phase 2 Baseline Weight  Phase 3 Baseline Weight   \n",
       "1                           NaN                      NaN   \n",
       "2                           NaN                      NaN   \n",
       "3                           NaN                      NaN   \n",
       "4                           NaN                      NaN   \n",
       "...                         ...                      ...   \n",
       "681109                    165.0                    165.0   \n",
       "681110                      NaN                      NaN   \n",
       "681111                    224.0                    228.0   \n",
       "681112                    224.0                    228.0   \n",
       "681113                    224.0                    228.0   \n",
       "\n",
       "                             c_wt                          p_gain  \\\n",
       "0       Phase-Specific CFB Weight  Phase Specific Percent Wt Gain   \n",
       "1                             NaN                             NaN   \n",
       "2                             NaN                             NaN   \n",
       "3                             NaN                             NaN   \n",
       "4                             NaN                             NaN   \n",
       "...                           ...                             ...   \n",
       "681109                        0.0                             0.0   \n",
       "681110                        NaN                             NaN   \n",
       "681111                       12.0                        5.263158   \n",
       "681112                        NaN                             NaN   \n",
       "681113                        4.0                        1.785714   \n",
       "\n",
       "                            bmi_cat  heart_rate              height_std  \\\n",
       "0       Body Mass Index Categorized  heart rate  Height - Standard Unit   \n",
       "1                               NaN         NaN                     NaN   \n",
       "2                               NaN         NaN                     NaN   \n",
       "3                               NaN         NaN                     NaN   \n",
       "4                               NaN         NaN                     NaN   \n",
       "...                             ...         ...                     ...   \n",
       "681109                          NaN        70.0                     NaN   \n",
       "681110                          3.0        84.0                    70.0   \n",
       "681111                          NaN        82.0                     NaN   \n",
       "681112                          3.0        80.0                    73.0   \n",
       "681113                          NaN        90.0                     NaN   \n",
       "\n",
       "                    weight_std  \n",
       "0       Weight - Standard Unit  \n",
       "1                          NaN  \n",
       "2                          NaN  \n",
       "3                          NaN  \n",
       "4                          NaN  \n",
       "...                        ...  \n",
       "681109                   165.0  \n",
       "681110                   189.0  \n",
       "681111                   240.0  \n",
       "681112                   220.0  \n",
       "681113                   228.0  \n",
       "\n",
       "[681114 rows x 1239 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all dfs which have promoted_subjectkey and a collection_title\n",
    "# This merges on all shared columns, doing outer to make sure all rows are kept. \n",
    "# NaNs will go in where info does not exist for that row.\n",
    "\n",
    "# Initial df \n",
    "merged_df = list(processed_data.values())[0]\n",
    "\n",
    "# Merge remaining dfs\n",
    "for key in list(processed_data.keys())[1:]:\n",
    "    merged_df = pd.merge(merged_df, processed_data[key], how='outer')\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bfc2887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDAR_INVYR649KT1       1398\n",
       "NDAR_INVKW099DZA       1276\n",
       "NDAR_INVUK248FD1       1257\n",
       "NDAR_INVUJ397VYA       1207\n",
       "NDAR_INVGM160JV7       1071\n",
       "                       ... \n",
       "NDAR_INVWX303CE3         66\n",
       "NDAR_INVJT616KT0         63\n",
       "NDAR_INVEG659ZPZ         62\n",
       "NDAR_INVKE735LYG         60\n",
       "promoted_subjectkey       1\n",
       "Name: promoted_subjectkey, Length: 1461, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take a look at how many rows there are for each promoted_subjectkey\n",
    "merged_df['promoted_subjectkey'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8336adea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 2nd row of variable descriptions.\n",
    "null_row = pd.DataFrame([np.nan] * len(merged_df.columns)).T\n",
    "null_row.columns = merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30872ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat merged_df with the NaN's as 2nd row\n",
    "merged_df= pd.concat([merged_df.iloc[:1], null_row, merged_df.iloc[1:]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20e035de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping for the variable descriptions\n",
    "variable_map = {\n",
    "    'EPS': 'Extrapyramidal symptoms',\n",
    "    'CGIS': 'clinical global impression scale; severity of psychopathology on a scale of 1 to 7',\n",
    "    'ECG' : 'electrocardiogram',\n",
    "    'QT': \"ECG reading; beginning of Q wave to end of T wave\",\n",
    "    'SF_12': 'Medical Outcome Study Short Form-12; 12 item questionnaire measures general health status and functioning',\n",
    "    'BRS':'Barnses Akathisia Scale; movement disorder severity',\n",
    "    'AE' : 'Adverse events',\n",
    "    'Calgary' : ' Calgary depression scare for Schizophrenia',\n",
    "    'DAI' : 'drug attitude inventory',\n",
    "    'ITAQ' : 'insight into treatment attitude questionnaire',\n",
    "    'WRAT-3' : 'wide range achievement test-3, reading subset',\n",
    "    'COWAT' : 'controlled oral word association test'\n",
    "    # Add more mappings\n",
    "}\n",
    "\n",
    "\n",
    "def variable_description(df, variable_map):\n",
    "    # Work only on the first two rows\n",
    "    first_two_rows = df.iloc[:2].copy()\n",
    "\n",
    "    # Loop through columns in the first row\n",
    "    for col in first_two_rows.columns:\n",
    "        first_row_value = first_two_rows.at[0, col]\n",
    "        \n",
    "        # Check if any of the words in variable_map are present in the first row value\n",
    "        for key, value in variable_map.items():\n",
    "            if pd.notna(first_row_value) and key in str(first_row_value):  \n",
    "\n",
    "                # Populate the second row with the mapped description \n",
    "                if pd.isna(first_two_rows.at[1, col]):\n",
    "                    first_two_rows.at[1, col] = value\n",
    "\n",
    "    # Update the original DataFrame for the first two rows\n",
    "    df.iloc[:2] = first_two_rows\n",
    "\n",
    "\n",
    "variable_description(merged_df, variable_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7894f5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "# test \n",
    "print(merged_df.columns.get_loc('b1_obj'))\n",
    "print(merged_df.columns.get_loc('epsmean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9aa8016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        sevscore  \\\n",
      "0  Total Movement Severity score   \n",
      "1                            NaN   \n",
      "2                            NaN   \n",
      "\n",
      "                                              brsobj                  epsmean  \\\n",
      "0                        BRS Obj/Subject Items Score     EPS Scale Mean Score   \n",
      "1  Barnses Akathisia Scale; movement disorder sev...  Extrapyramidal symptoms   \n",
      "2                                                NaN                      NaN   \n",
      "\n",
      "                                b1_score                      b1_index  \\\n",
      "0  Movement Severity Score Phase 1/1A BL  Severity Index Phase 1/1A BL   \n",
      "1                                    NaN                           NaN   \n",
      "2                                    NaN                           NaN   \n",
      "\n",
      "                                              b1_obj  \n",
      "0                      BRS Obj/Subject Phase 1/1A BL  \n",
      "1  Barnses Akathisia Scale; movement disorder sev...  \n",
      "2                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(merged_df.iloc[:3, 70:76])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1adee2c500c5fd89defc3f5ede4bff28528af3a042d92370d59dd6238d9630bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
